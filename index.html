<!DOCTYPE html>
<html>
  <head>
  </head>
  <body style="width: 60%; margin: 0 auto; padding-top: 2%">

    <table style="width: 100%">
      <tr>
        <td style="text-align: left">
          <img src="Anmol.jpg" alt="Anmol Image" style="border-radius: 100%">
        </td>
        <td style="text-align: right">
          <span>Anmol Rastogi</span><br>
          <span><strong>Senior Software Engineer</strong></span><br>
          <span><strong>Legato Health Technologies</strong></span><br>
          <span>Contact - 7417014771</span><br>
          <span>email - rastogianmol0@gmail.com</span><br>
          <a target="_blank" href="https://www.linkedin.com/in/ranmol">https://www.linkedin.com/in/ranmol</a>
        </td>
      </tr>
    </table>
    <hr Size="3" noshade>
      <p>Assimilated 3 Years of Techno-Functional IT Experience in Providing Strategic and Consulting Support for Big Data Projects through Spark Development using agile methodology and contributing in PMO Roles for project planning,
        data analysis and delivery.</p>
    <hr>

        <h4>PROFESSIONAL SUMMARY</h4>
        <ul style="padding-bottom: 2%;">
          <li>Professional with 3 years in Life sciences and Health Care Industry as Spark Developer, Project Management, and
Agile Scrum methodology practitioner.</li>
          <li>Spark Developer: Proven ability to work with huge volume of data, transformations and data analysis using spark
& hive.</li>
          <li>Handled Business escalations & managed day-to-day operations of project with Requirement analysis and Delegation
of tasks, Delivery of Modules and enablement of new resources.</li>
        </ul><hr>

        <h4>PERSONAL STANDARDS</h4>
        <ul style="padding-bottom: 2%;">
            <li>Proficient communication skills to understand requirement and delegate tasks.</li>
            <li>Interpersonal skills with ability to work with cross functional teams located across geographies.</li>
            <li>Ability to prioritize tasks, and quality to adopt to rapidly changing environment.</li>
            <li>High attention to detail, self-motivated, and flexible.</li>
        </ul><hr>

        <h4>TECHNOLOGY FORTE</h4>
        <table style="width: 100%">
          <tr>
            <td>Operating Systems</td>
            <td>Windows, Linux, CentOS</td>
          </tr>
          <tr>
            <td>Languages</td>
            <td>SparkSQL, Scala, HiveQL</td>
          </tr>
          <tr>
            <td>DBMS</td>
            <td>Hive, PrestoDb, Microsoft Access, Oracle DB</td>
          </tr>
          <tr>
            <td>Tools and Utilities</td>
            <td>Adobe Photoshop, MS-word, MS-Excel, PowerPoint, Cloudera VM</td>
          </tr>
          <tr>
            <td>Major Technologies</td>
            <td>Hadoop, Spark</td>
          </tr>
          <tr>
            <td>Learning in Progress</td>
            <td>AWS</td>
          </tr>
        </table>
<hr>
        <h4>ACADEMIC CREDENTIALS</h4>
        <p>Bachelor of Computer Applications, Graphic Era University, Dehradun, India</p>
        <table style="width: 35%">
          <tr>
            <td>Year</td>
            <td>2014-2017</td>
          </tr>
          <tr>
            <td>Percentage</td>
            <td>9.05</td>
          </tr>
        </table>
<hr>
        <h4>PROFESSIONAL CONTOUR</h4>
        <table style="width: 100%">
          <tr>
            <td><strong>Project Name</strong></td>
            <td><strong>California Aggregated Care Organizations (CA ACO)</strong></td>
          </tr>
          <tr>
            <td>Role</td>
            <td>Spark Developer</td>
          </tr>
          <tr>
            <td>Organization</td>
            <td>Legato Health Technologies Pvt. Ltd.</td>
          </tr>
          <tr>
            <td>Duration</td>
            <td>April 2019 – Current</td>
          </tr>
          <tr>
            <td>Team Size</td>
            <td>22</td>
          </tr>
          <tr>
            <td>Software</td>
            <td>SparkSQL, Scala, HiveQL, Spark-shell, Shell Scripting</td>
          </tr>
        </table>
        <h5>Responsibilities</h5>
        <ul style="padding-bottom: 2%;">
          <li>Working with 20 members from Offshore in development and analysis</li>
          <li>Working with project owners for Project planning, setting up user stories and gathering the business requirement</li>
          <li>Accountable for translating business requirements to the IT team and work along with them to deliver as
          expected and beyond</li>
          <li>Responsible for Daily team stand-ups and reporting of team status</li>
          <li>Involved with the team for framework design and approach planning</li>
        </ul>

        <table style="width: 100%">
          <tr>
            <td><strong>Project Name</strong></td>
            <td><strong>Provider Analytics Data platform - CA ACO</strong></td>
          </tr>
          <tr>
            <td>Role</td>
            <td>Spark Developer</td>
          </tr>
          <tr>
            <td>Organization</td>
            <td>Deloitte Consulting India Pvt. Ltd.</td>
          </tr>
          <tr>
            <td>Duration</td>
            <td>June 2018 – April 2019</td>
          </tr>
          <tr>
            <td>Team Size</td>
            <td>12</td>
          </tr>
          <tr>
            <td>Software</td>
            <td>SparkSQL, Scala, HiveQL, Spark-shell, Shell Scripting</td>
          </tr>
        </table>
        <h5>Responsibilities</h5>
        <ul style="padding-bottom: 2%;">
          <li>Worked on developing extracts using SparkSQL, Scala and Hive Query Language.</li>
          <li>Developed Shell Scripts for Secure File transfer.</li>
          <li>Worked with Control-M tools for job scheduling.</li>
          <li>Got involved in Requirement gathering, design, coding, testing for the extracts.</li>
        </ul>

        <table style="width: 100%">
          <tr>
            <td><strong>Project Name</strong></td>
            <td><strong>Provider Analytics Data Platform – Lab Benchmarks</strong></td>
          </tr>
          <tr>
            <td>Role</td>
            <td>Spark & Hive Developer</td>
          </tr>
          <tr>
            <td>Organization</td>
            <td>Deloitte Consulting India Pvt. Ltd.</td>
          </tr>
          <tr>
            <td>Duration</td>
            <td>January 2018 to May 2018</td>
          </tr>
          <tr>
            <td>Team Size</td>
            <td>7</td>
          </tr>
          <tr>
            <td>Software</td>
            <td>SparkSQL, Hive SQL, Shell Scripting</td>
          </tr>
        </table>
        <h5>Responsibilities</h5>
        <ul style="padding-bottom: 2%;">
          <li>Preparing Hive QLs to Transform Data and perform logical operations as required.</li>
          <li>Preparing shell scripts to automate process.</li>
          <li>Achieved 10% decrease in manual intervention during Loads using shell programming.</li>
          <li>Prepared Scala Code for faster execution of task.</li>
        </ul>


                <table style="width: 100%">
                  <tr>
                    <td><strong>Project Name</strong></td>
                    <td><strong>Provider Analytics Data Platform – Common Data Layer</strong></td>
                  </tr>
                  <tr>
                    <td>Role</td>
                    <td>Spark Developer, Tester</td>
                  </tr>
                  <tr>
                    <td>Organization</td>
                    <td>Deloitte Consulting India Pvt. Ltd.</td>
                  </tr>
                  <tr>
                    <td>Duration</td>
                    <td>August 2017 to December 2017</td>
                  </tr>
                  <tr>
                    <td>Team Size</td>
                    <td>10</td>
                  </tr>
                  <tr>
                    <td>Software</td>
                    <td>Spark-SQL, Spark with Scala, Hive-QL, Spark-shell</td>
                  </tr>
                </table>
                <h5>Responsibilities</h5>
                <ul style="padding-bottom: 2%;">
                  <li>Development of Spark SQL queries based on the requirements.</li>
                  <li>Executing Test Queries and maintaining the Data Quality Check.</li>
                  <li>Loading Data from Different Data Sources to Hadoop using Sqoop.</li>
                  <li>Interaction with Process owners and Client on day-to-day basis</li>
                </ul>

                <h5>Achievements</h5>
                <p  style="padding-bottom: 2%;">Provide and managed high end productive results.</p>

  </body>
</html>
